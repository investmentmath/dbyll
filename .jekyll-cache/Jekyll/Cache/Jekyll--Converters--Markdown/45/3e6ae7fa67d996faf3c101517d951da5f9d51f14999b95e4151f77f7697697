I"ƒ5<p><em>The martingale representation problem in its simplest form is the following. Given a filtration generated by a martingale <span class="math inline">\(M\)</span> and given another martingale <span class="math inline">\(N\)</span> adapted to the filtration, can we express <span class="math inline">\(N\)</span> as a stochastic integral with <span class="math inline">\(M\)</span> as the integrator? The martingale <span class="math inline">\(N\)</span> is generally closed, i.e.Â it can be expressed as the conditional expectation of a terminal variable <span class="math inline">\(N_{T}\)</span>. In this case, the integrand <span class="math inline">\(H_{t}\)</span> of the stochastic integral representation is heuristically the sensitivity of <span class="math inline">\(N_{T}\)</span> to the shock <span class="math inline">\(dM_{t}\)</span>.The Brownian filtration is the most important example where a Martingale Representation Theorem holds.</em></p>
<hr />
<p>The theory of martingale representation is concerned with the following problem.</p>
<p>Consider a filtered probability space <span class="math inline">\((\Omega,{\cal F},P)\)</span> with index space <span class="math inline">\(\mathbb{T}=[0,T]\)</span> where <span class="math inline">\(T\)</span> is finite. Such a space supports a set of martingales <span class="math inline">\({\cal M}\)</span> against which we can compute stochastic integrals for predictable integrands.</p>
<p>We are given an <span class="math inline">\({\cal F}_{T}\)</span>-measurable random variable <span class="math inline">\(X_{T}\)</span>. It induces a martingale <span class="math inline">\((E_{t}[X_{T}])_{t \in \mathbb{T}}\)</span>. This process represents, within the model, the anticipation of <span class="math inline">\(X_{T}\)</span> at any point <span class="math inline">\(t\)</span>. The changes in <span class="math inline">\(E_{t}[X_{T}]\)</span> as a function of <span class="math inline">\(t\)</span> reflect the real time acquisition of information on <span class="math inline">\(X_{T}\)</span>. New information comes as surprises as modeled in martingale differences (see <a href="/math/2013/04/24/martingales.html" title="MARTINGALES">this post</a>). Heuristically, martingale representation asks the following question: can we represent the surprises in <span class="math inline">\((E_{t}[X_{T}])_{t \in \mathbb{T}}\)</span> for any <span class="math inline">\(X_{T}\)</span> as a linear function of the (contemporaneous) surprises embedded in our set <span class="math inline">\({\cal M}\)</span> of martingales. More precisely, can we represent the martingale <span class="math inline">\((E_{t}[X_{T}])_{t \in \mathbb{T}}\)</span> as a sum of stochastic integrals against some martingales in <span class="math inline">\({\cal M}\)</span>.</p>
<p>A striking incarnation of this issue is found when the filtered probability space is generated by a Brownian motion<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>.</p>
<p><strong>Theorem (Martingale Representation for the Brownian Filtration)</strong>:<em>Let <span class="math inline">\({\cal F}\)</span> be the smallest right continuous and complete filtration generated by a univariate Brownian motion <span class="math inline">\((B_{t})_{t \in \mathbb{T}}\)</span>. Let <span class="math inline">\(X_{T}\)</span> be an <span class="math inline">\({\cal F}_{T}\)</span>-measurable random variable with finite second moment <span class="math inline">\(E_{0}[X_{T}^{2}]&lt;\infty\)</span>. Then there is a predictable process <span class="math inline">\((H_{t})_{t \in \mathbb{T}}\)</span> with <span class="math inline">\(\int_{0}^{T}H_{s}^{2}ds&lt;\infty\)</span> such that:<span class="math display">\[X_{T}=E[X_{T}]+\int_{0}^{T}H_{s}dB_{s}.\]</span></em></p>
<p><span class="math inline">\({\scriptstyle \blacksquare}\)</span></p>
<p>In the same context as above, we have a simple yet important corollary:</p>
<p><strong>Corollary:</strong> <em>For any square integrable<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>right continuous martingale <span class="math inline">\((M_{t})_{t \in \mathbb{T}}\)</span> with <span class="math inline">\(M_{0}=0\)</span>, there exists a predictable process <span class="math inline">\((H_{t})_{t \in \mathbb{T}}\)</span> with <span class="math inline">\(\int_{0}^{T}H_{s}^{2}ds&lt;\infty\)</span> such that:<span class="math display">\[M_{t}=\int_{0}^{t}H_{s}dB_{s}.\]</span></em></p>
<p><span class="math inline">\({\scriptstyle \blacksquare}\)</span></p>
<p>In other words, all square integrable right continuous martingales with initial value zero are Brownian stochastic integrals. Actually, in our context, all square integrable martingales have a version which is still a martingale and is right continuous with left limits. They can therefore be represented as Brownian integrals. Since Brownian integrals have continuous trajectories, all square integrable martingales in this setup have a continuous version. Finally, one can extend the above result to show that all local martingales can be represented as a Brownian stochastic integral.</p>
<p>It is quite easy to generate setups where the filtration is the minimal filtration generated by a given martingale <span class="math inline">\((M_{t})_{t \in \mathbb{T}}\)</span>, and yet, the filtration supports other martingales which cannot be written as sotchastic integrals of <span class="math inline">\((M_{t})_{t \in \mathbb{T}}\)</span>. In <a href="/math/2013/04/24/martingales.html" title="MARTINGALES">this post</a>, an example is given where <span class="math inline">\(\mathbb{T}\)</span> is discrete and <span class="math inline">\((M_{t})_{t \in \mathbb{T}}\)</span> has standardized gaussian increments. If, on the other hand, <span class="math inline">\((M_{t})_{t \in \mathbb{T}}\)</span> has binomial increments, the martingale representation holds with the set <span class="math inline">\({\cal M}\)</span> consisting of <span class="math inline">\((M_{t})_{t \in \mathbb{T}}\)</span>. A solution to recover a martingale representation result when it does not hold for <span class="math inline">\({\cal M}=\{ (M_{t})_{t \in \mathbb{T}} \}\)</span> is to add other martingales in <span class="math inline">\({\cal M}\)</span>, based on higher order moments of <span class="math inline">\((M_{t})_{t \in \mathbb{T}}\)</span> for instance. Indeed, the problems generally come from the difficulty of generating non linear functions of <span class="math inline">\((M_{t})_{t \in \mathbb{T}}\)</span> through the stochastic integral which, in the end, is just a linear reweighting of the increments of <span class="math inline">\((M_{t})_{t \in \mathbb{T}}\)</span>.</p>
<p>Given the above remarks, the Brownian martingale representation theorem looks like a nice accident. I now sketch the proof. An <span class="math inline">\({\cal F}_{T}\)</span>-measurable random variable is, roughly speaking, a function of the increments of the Brownian motion. A simple example would be a function <span class="math inline">\(f(B_{t_{1}}-B_{t_{0}},\cdots,B_{t_{n}}-B_{t_{n-1}})\)</span> where the time intervals <span class="math inline">\([t_{i},t_{i-1}]\)</span> do not overlap. Such functions can however be recovered through Fourier transform from products of complex exponentials<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>: <span class="math display">\[\exp(iu_{1}(B_{t_{1}}-B_{t_{0}}))\cdots
\exp(iu_{n}(B_{t_{n}}-B_{t_{n-1}})).\]</span> It is conceivable that if a martingale representation were to hold for such a function, the representation could be extended by limiting arguments to all <span class="math inline">\({\cal F}_{T}\)</span>-measurable random variables. However, Ito calculus implies that: <span class="math display">\[\exp(iu_{k}(B_{t}-B_{t_{k-1}})+\frac{1}{2}u_{k}^{2}(t-t_{k-1}))=1+\]</span> <span class="math display">\[\int_{t_{k-1}}^{t_{k}}iu_{k}\exp(iu_{k}(B_{s}-B_{t_{k-1}})+\frac{1}{2}u_{k}^{2}(s-t_{k-1}))dB_{s},\]</span> i.e. <span class="math display">\[d\left(\exp(iu_{k}(B_{t}-B_{t_{k-1}})+\frac{1}{2}u_{k}^{2}(t-t_{k-1}))\right)=\exp(iu_{k}(B_{t}-B_{t_{k-1}})+\frac{1}{2}u_{k}^{2}(t-t_{k-1}))dB_{t}.\]</span> This complex exponential is a geometric martingale with initial value <span class="math inline">\(1\)</span> at <span class="math inline">\(t=t_{k-1}\)</span>.</p>
<p>From this, we get (taking <span class="math inline">\(t=t_{k}\)</span> and rearranging terms): <span class="math display">\[Z_{k-1}=\exp(iu_{k}(B_{t_{k}}-B_{t_{k-1}}))=\exp(-\frac{1}{2}u_{k}^{2}(t_{k}-t_{k-1}))+\]</span> <span class="math display">\[\int_{t_{k-1}}^{t_{k}}iu_{k}\exp(iu_{k}(B_{s}-B_{t_{k-1}})+\frac{1}{2}u_{k}^{2}(s-t_{k}))dB_{s}\]</span> <span class="math display">\[=F_{k-1}+\int_{t_{k-1}}^{t_{k}}H_{k-1}(s)dB_{s},\]</span> where <span class="math inline">\(Z_{k-1}\)</span> is the random variable of interest, <span class="math inline">\(F_{k-1}\)</span> is a function of non random parameters only and <span class="math inline">\(H_{k-1}\)</span> is the integrand within the stochastic integral. We thus have the right representation for a single exponential of a Brownian increment.</p>
<p>When multiplying two such terms attached to non overlapping intervals, say <span class="math inline">\([t_{k-1},t_{k}]\)</span> and <span class="math inline">\([t_{k},t_{k+1}]\)</span>, the product rule entails no covariation terms because the stochastic integrals refer to non overlapping time intervals: <span class="math display">\[[\int_{t_{k-1}}^{t_{k}}H_{k-1}(s)dB_{s},\int_{t_{k}}^{t_{k+1}}H_{k}(s)dB_{s}]=0.\]</span> We thus have the following representation for the product: <span class="math display">\[Z_{k-1}Z_{k}=F_{k-1}F_{k}+\int_{t_{k-1}}^{t_{k}}F_{k}H_{k-1}(s)dB_{s}+\int_{t_{k}}^{t_{k+1}}Z_{k-1}H_{k}(s)dB_{s},\]</span> which still has the right structure. It is now clear that any product involving a finite number of such exponentials involving non overlapping intervals has a martingale representation. The rest of the proof is a matter of spelling out the limiting arguments that allow to extend<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> the representation to any function <span class="math inline">\(f(B_{t_{1}}-B_{t_{0}},\cdots,B_{t_{n}}-B_{t_{n-1}})\)</span> and then to any <span class="math inline">\({\cal F}_{T}\)</span>-measurable random variable (through a density argument).</p>
<p>In the Brownian context thus, Brownian integrals allow to generate all the local martingales supported by the filtration<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>. Amongst them are all the martingales generated by moments <span class="math inline">\(B^{\alpha}_{t}\)</span>, for instance <span class="math inline">\(X_{t}=B^{2}_{t}-t=2\int_{0}^{t}B_{s}dB_{s}\)</span>.</p>
<p>A striking illustration of this involves Hermite polynomial functions. If <span class="math inline">\(H_{n}(x,y)=\left(\frac{y}{2}\right)^{\frac{n}{2}}h_{n}(\frac{x}{\sqrt{2y}})\)</span> (<span class="math inline">\(n \geq 0\)</span>) where <span class="math inline">\(h_{n}(\cdot)\)</span> are Hermite polynomials<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>, then <span class="math inline">\(H_{n}(B_{t},t)\)</span> are martingales and we have the following integral representation: <span class="math display">\[H_{n}(B_{t},t)=\int_{0}^{t}nH_{n-1}(B_{u},u)dB_{u
}=n!\int_{0}^{t}\int_{0}^{t_{n-1}}\cdots\int_{0}^{t_{1}}dB_{s}dB_{t_{1}}
\cdots dB_{t_{n-1}}.\]</span> This result can be found for instance in Chung[1990], chapter 6.</p>
<p>Reference: Chung K.L and R.J. Williams, 1990 : <em>An introduction to Stochastic Integration</em>, Birkhauser.</p>
<p>Bass R.F., 2011, <em>Stochastic Processes</em>, Cambridge University Press</p>
<h2 id="links">Links</h2>
<ul>
<li><a href="/assets/pdfs/2013-10-27-martingale-representation.pdf">Link to pdf</a></li>
</ul>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>The following results can be found in Bass[2011], p.Â 80.<a href="#fnref1" class="footnote-back" role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn2" role="doc-endnote"><p><span class="math inline">\(E_{0}[M_{T}^{2}]&lt;\infty\)</span>.<a href="#fnref2" class="footnote-back" role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn3" role="doc-endnote"><p>In our context, the Fourier transform amounts to mixing functions indexed by <span class="math inline">\((u_{1},\ldots,u_{n})\)</span> using a weighting scheme <span class="math inline">\({\hat f}(u_{1},\ldots,u_{n})\)</span>.<a href="#fnref3" class="footnote-back" role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn4" role="doc-endnote"><p>Through the Fourier transform, which amounts to integrating the integral representations attached to different parameters <span class="math inline">\((u_{1},\ldots,u_{n})\)</span>, using a weighting scheme <span class="math inline">\({\hat f}(u_{1},\ldots,u_{n})\)</span>.<a href="#fnref4" class="footnote-back" role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn5" role="doc-endnote"><p>It is important that the filtration be the minimal filtration generated by the Brownian motion, i.e.Â the smallest right continuous and complete filtration generated by the Brownian motion.<a href="#fnref5" class="footnote-back" role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn6" role="doc-endnote"><p><span class="math inline">\(H_{0}(x,y)=1,H_{1}(x,y)=x,H_{2}(x,y)=x^{2}-y,\ldots\)</span><a href="#fnref6" class="footnote-back" role="doc-backlink">â†©ï¸Ž</a></p></li>
</ol>
</section>
:ET