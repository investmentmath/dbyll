I"á7<p><em>Building on the <a href="/finance/2013/04/06/portfolio-returns.html" title="PORTFOLIO RETURNS">portfolio return post</a>, this article describes the stochastic inregral <span class="math inline">\(\int_{0}^{\cdot}H_{u}dM_{u}\)</span> of an integrand <span class="math inline">\(H\)</span> against a martingale <span class="math inline">\(M\)</span> as a martingale transform. The integral re-weights the increments of <span class="math inline">\(M\)</span> using a system of â€˜predeterminedâ€™ weights in such a way that the resulting process remains a martingale. The preservation of the martingale property is a key requirement of the standard stochastic integration theory. The sensitivity of the resulting martingale <span class="math inline">\(\int_{0}^{\cdot}H_{u}dM_{u}\)</span> with respect to the infinitesimal increments of <span class="math inline">\(M\)</span> is an instanciation of the concept of Malliavin derivative. The post ends by considering the martingale representation property which plays a key role in financial theory.</em></p>
<hr />
<h1 id="martingale-transforms">Martingale Transforms</h1>
<p>The <a href="/finance/2013/04/06/portfolio-returns.html" title="PORTFOLIO RETURNS">portfolio return post</a> took the perspective that a portfolio is a weighting scheme applied to the returns of the available instruments. The weights are chosen as a function of the information set of the portfolio manager. This leads to a staggered information structure: weights depend on past information and cannot anticipate future surprises in returns.</p>
<p>Martingale transforms can be understood from this perspective. Assume that we are given a filtered probability space <span class="math inline">\((\Omega, {\cal F},({\cal F}_{t})_{t \in \mathbb{T}},P)\)</span> together with a martingale <span class="math inline">\((M_{t})_{t \in \mathbb{T}}\)</span>. Letâ€™s assume a discrete time setting <span class="math inline">\(\mathbb{T}=\mathbb{N}\)</span>. The martingale differences <span class="math inline">\(\Delta M_{t}=M_{t}-M_{t-1}\)</span> are our surprises. Letâ€™s weigh them using a <span class="math inline">\({\cal F}_{t-1}\)</span> random variable <span class="math inline">\(H_{t-1}\)</span>. We get the reweighted martingale difference: <span class="math display">\[H_{t-1}\Delta
M_{t}=H_{t-1}(M_{t}-M_{t-1}),\]</span> which is still a martingale difference in the sense that: <span class="math display">\[E_{t-1}[H_{t-1}\Delta
M_{t}]=H_{t-1}E_{t-1}[\Delta M_{t}]=0.\]</span> Cumulating these differences leads to a new martingale <span class="math inline">\((\tilde{M}_{t})_{t \in \mathbb{T}}\)</span>: <span class="math display">\[\tilde{M}_{t}=\sum_{k=1}^{t}H_{k-1}\Delta
M_{k}\]</span> which is centered <span class="math inline">\(E_{0}[\tilde{M}_{t}]=0\)</span>. This is the discrete time stochastic integral.</p>
<p>In continuous time (<span class="math inline">\(\mathbb{T}=\mathbb{R}_{+}\)</span>), the staggered information structure is more subtle. The key to the construction of the stochastic integral is that we want it to preserve the martingale property. The construction starts with the definition of simple weights, i.e.Â piecewise constant weighting schemes, where discontinuities take place at stopping times (<span class="math inline">\(T_{i})_{i \in \mathbb{N}},\, T_{0}=0\)</span>: <span class="math display">\[H_{t}=\sum_{i=0}^{N-1}H^{i}1_{(T_{i},T_{i+1}]}(t),\]</span> where <span class="math inline">\(H^{i}\)</span> is <span class="math inline">\({\cal F}_{T_{i}}\)</span> measurable. The key point is that the weight chosen at date <span class="math inline">\(T_{i}\)</span> is in place right after <span class="math inline">\(T_{i}\)</span>, and up until <span class="math inline">\(T_{i+1}\)</span>. In particular, at <span class="math inline">\(T_{i}\)</span>, <span class="math inline">\(H^{i-1}\)</span> prevails. When applied to the martingale differences, the simple weighting scheme delivers for each <span class="math inline">\(\omega\)</span>: <span class="math display">\[\tilde{M}_{t}=\int_{0}^{t}H_{u}dM_{u}:=\sum_{i=0}^{J(t)-1}H^{i}(M_{T_{i+1}}-M_{T_{i}})+H^{J(t)}(M_{t}-M_{T_{J(t)}}),\]</span> where <span class="math inline">\(J(t)(\omega)\)</span> is set such that <span class="math inline">\(T_{J(t)}(\omega) \leq t &lt; T_{J(t)+1}(\omega)\)</span>. The staggered information structure implies that each increment is conditionally centered, and <span class="math inline">\((\tilde{M}_{t})\)</span> is a centered (<span class="math inline">\(E_{0}[\tilde{M}_{t}]=0\)</span>) martingale as in the discrete time case.</p>
<p>The theory of stochastic integrals consists in extending this construction to more general weighting schemes while preserving the staggered information structure. We will be evasive about the technical conditions needed for stochastic integration to work. We will however keep the information structure in mind. Integrands<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> cannot anticipate on information. Adapted continuous processes (i.e.Â each <span class="math inline">\(H_{t}\)</span> is <span class="math inline">\({\cal F}_{t}\)</span> measurable and trajectories are continuous) are suitable integrands. When the underlying martingale is allowed to jump (while being continuous on the right with limits on the left - cadlag), the integrands can also be allowed to jump provided they are caglad (continuous on the left with limits on the right - see the post on portfolio returns). These requirements are needed to ensure that the stochastic integral of a valid integrand against a martingale remains a martingale.</p>
<h1 id="sensitivity-of-a-martingale-to-the-underlying-shocks">Sensitivity of a martingale to the underlying shocks</h1>
<p>A martingale <span class="math inline">\((M_{t})_{t \in \mathbb{T}}\)</span> is the additive accumulation of the associated shocks, whether these are true differences <span class="math inline">\((\Delta M_{t})\)</span> as in the discrete time case or infinitesimal idealizations <span class="math inline">\((dM_{t})\)</span>. I use the discrete time case in what follows. Any particular shock <span class="math inline">\(\Delta M_{u}\)</span> has a fully persistent impact on the subsequent level <span class="math inline">\((M_{t})_{t \geq u}\)</span> of the martingale. We could write this as:<span class="math display">\[\frac{\partial
M_{t}}{\partial \Delta M_{u}}=1,\, t \geq u.\]</span> We can see the stochastic integral as a method to create a new martingale with a different sensitivity to the underlying shocks. The new sensitivity is <em>a priori</em> given by <span class="math inline">\(H_{u-1}\)</span>. This is right when the integrand is a deterministic function, in which case we thus have:<span class="math display">\[\frac{\partial
\tilde{M}_{t}}{\partial \Delta M_{u}}=H_{u-1},\, t \geq u.\]</span> When integrands are stochastic however, <span class="math inline">\(H_{u-1}\)</span> cannot measure the overall impact of the shock on the future level of the new martingale. Indeed, the shock might alter the integrand <span class="math inline">\(H_{t}\)</span> at a future date. We would like to write:<span class="math display">\[\frac{\partial \tilde{M}_{t}}{\partial
\Delta M_{u}}=H_{u-1}+\sum_{u+1}^{t}\frac{\partial
H_{v-1}}{\partial \Delta M_{u}}\Delta M_{v},\, t \geq u.\]</span> The meaning of <span class="math inline">\(\frac{\partial H_{v-1}}{\partial \Delta M_{u}}\)</span> is however quite unclear unless <span class="math inline">\(H_{v-1}\)</span> can itself be described as a stochastic integral with deterministic integrand! The martingale <span class="math inline">\((\tilde{M}_{t})_{t \in \mathbb{T}}\)</span> would then be a double stochastic integral.</p>
<p>What is sketched above is precisely the program of defining Malliavin derivatives, initially developed for Brownian filtrations and integrals. The program can be carried out because in the Brownian filtration, all square integrable random variables can be approximated as a multiple stochastic integral<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>. As such, their derivatives with respect to the underlying Brownian shocks can be computed. We will not need the full force of this theory, but we will keep in mind the idea. We will often use deterministic integrands for which Malliavin derivatives are trivial. Stochastic Brownian integrals with deterministic integrands are Gaussian variables. They are extremely handy because they allow to express a wide range of phenomena while permitting analytical computation.</p>
<h1 id="martingales-and-martingale-representation">Martingales and martingale representation</h1>
<p>Readers with a mathematical inclination could raise the following problem. Stochastic integrals allow to produce new martingales from an initial one. Can we produce all martingales in this way?</p>
<p>Letâ€™s then start from a filtered probability space as above, with the filtration being the filtration generated by a given martingale <span class="math inline">\((M_{t})_{t \in \mathbb{T}}\)</span>. We take <span class="math inline">\(\mathbb{T}\)</span> to be an interval within <span class="math inline">\(\mathbb{N}\)</span> or <span class="math inline">\(\mathbb{R}\)</span>. We therefore start with a minimal setup: a single martingale described in the most parsimonious filtered probability space which can support it. We can now define new martingales using stochastic integration based on suitably adapted integrands. We thereby get a wealth of new (centered) martingales as stochastic integrals. On the other hand, any <span class="math inline">\({\cal F}_{T}\)</span> integrable variable <span class="math inline">\(X_{T}\)</span> with mean <span class="math inline">\(E_{0}[X_{T}]=0\)</span> defines a centered martingale (<span class="math inline">\(E_{t}[X_{T}]\)</span>). The latter set of centered martingales is <em>a priori</em> larger than the previous set of centered martingales defined through stochastic integrals against the initial martingale. Indeed a stochastic integral is a closed centered martingale:<span class="math display">\[\int_{0}^{t}H_{u}dM_{u}=E_{t}[\int_{0}^{T}H_{u}dM_{u}].\]</span> The question is then whether the inclusion is strict<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>. It turns out again that in the Brownian filtration, the two sets of martingales coincide. Martingales can be represented as stochastic integrals: the martingale representation theorem holds. A similar result holds when the underlying martingale is the compensated Poisson process. There are however plenty of cases where the inclusion is strict. I give below two trivial examples that shed some light on what is going on.</p>
<p>I assume an extreme discrete time case, with only two dates <span class="math inline">\(T=0,1\)</span>. The sigma algebra <span class="math inline">\({\cal F}_{0}\)</span> is trivial and <span class="math inline">\({\cal F}_{1}\)</span> is the sigma algebra generated by a variable <span class="math inline">\(\epsilon\)</span>. Stochastic integrals are just proportional functions of <span class="math inline">\(\epsilon\)</span> since <span class="math inline">\({\cal F}_{0}\)</span> random variables (integrands) are constant. Assume <span class="math inline">\(\epsilon\)</span> is a standardized Gaussian variable. Consider <span class="math inline">\(X_{1}=\epsilon^{2}-1\)</span>. This defines a centered martingale which is not linear in <span class="math inline">\(\epsilon\)</span>. The martingale representation theorem does not hold.</p>
<p>If instead, <span class="math inline">\(\epsilon\)</span> equals a binomial variable taking values <span class="math inline">\(+1\)</span> with probability <span class="math inline">\(1/2\)</span> and <span class="math inline">\(-1\)</span> with probability <span class="math inline">\(1/2\)</span>, the martingale representation theorem holds. Indeed, any centered <span class="math inline">\({\cal F}_{1}\)</span> measurable variable is defined by two values <span class="math inline">\(X_{1}(1)\)</span> and <span class="math inline">\(X_{1}(-1)\)</span> such that:<span class="math display">\[\frac{1}{2}X_{1}(-1)+\frac{1}{2}X_{1}(1)=0.\]</span> Thus:<span class="math display">\[X_{1}(-1)=-X_{1}(1),\]</span> and:<span class="math display">\[X_{1}=X_{1}(1)\epsilon,\]</span> which is a stochastic integral since <span class="math inline">\(X_{1}(1)\)</span> is a constant.</p>
<p>This gives a good sense of why the compensated Poisson model has a martingale representation theorem. In the Brownian case, it is clear that continuous time plays an important role. One can perhaps close this post by noting that in this case: <span class="math display">\[M_{1}^{2}-1=\int_{0}^{1}M_{t}dM_{t}.\]</span> Moments shifted so as to be centered and more generally centered non linear functions of <span class="math inline">\(M_{1}\)</span> can be obtained as stochastic integrals. Continuous time does achieve a few miracles!</p>
<h2 id="links">Links</h2>
<ul>
<li><a href="/assets/pdfs/2013-05-02-stochastic-integrals-as-martingale-transforms.pdf">Link to pdf</a></li>
</ul>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>The weighting function is called the integrand while the underlying martingale is called the integrator.<a href="#fnref1" class="footnote-back" role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn2" role="doc-endnote"><p>See for instance D. Nualart, <em>The Malliavin Calculus and Related Topics</em>, Springer.<a href="#fnref2" class="footnote-back" role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn3" role="doc-endnote"><p>This question has an important interpretation in finance, in a broader but related context. In a market model, if all terminal pay-offs can be derived as a porfolio value (i.e.Â a stochastic integral) where the portfolio trades underlying financial instruments, the market is said to be complete. Completeness therefore means, loosely speaking, that a representation theorem holds with respect to the tradable instruments.<a href="#fnref3" class="footnote-back" role="doc-backlink">â†©ï¸Ž</a></p></li>
</ol>
</section>
:ET